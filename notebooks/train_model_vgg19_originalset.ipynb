{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas de TensorFlow y Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16, VGG19\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import (Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization)\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Bibliotecas de visualización\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Bibliotecas de procesamiento de datos y métricas\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rutas de los conjuntos de datos\n",
    "train_dir = '../data/train'\n",
    "valid_dir = '../data/valid'\n",
    "test_dir = '../data/test'\n",
    "\n",
    "# Parámetros\n",
    "img_height, img_width = 244, 244 \n",
    "batch_size = 32\n",
    "\n",
    "# Aumento de datos para el conjunto de entrenamiento\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Sólo reescalar para validación y prueba\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Generadores\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    valid_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False  # Para evaluar correctamente\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_vgg = VGG19(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg = Sequential([\n",
    "    base_model_vgg,\n",
    "    Flatten(),\n",
    "\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "\n",
    "    Dense(train_generator.num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "# Congelar las capas del modelo base para no entrenarlas de nuevo\n",
    "base_model_vgg.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilar el modelo (puedes ajustar el optimizador o la tasa de aprendizaje según sea necesario)\n",
    "model_vgg.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model_vgg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el modelo con tus datos\n",
    "history = model_vgg.fit(train_generator, \n",
    "                    validation_data=valid_generator, \n",
    "                    epochs=20, \n",
    "                    steps_per_epoch = train_generator.samples // batch_size,\n",
    "                    validation_steps = valid_generator.samples // batch_size,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar en el conjunto de prueba\n",
    "val_loss, val_accuracy = model_vgg.evaluate(valid_generator)\n",
    "print(f\"Validation accuracy: {val_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta a tus datos\n",
    "test_dir = '../data/test'\n",
    "\n",
    "# Preprocesamiento del conjunto de prueba\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False  # Importante para obtener las etiquetas en el mismo orden\n",
    ")\n",
    "\n",
    "# Obtener las predicciones del modelo\n",
    "predictions = model_vgg.predict(test_generator)\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Obtener las etiquetas verdaderas\n",
    "y_true = test_generator.classes\n",
    "\n",
    "# Obtener los nombres de las clases\n",
    "class_labels = list(test_generator.class_indices.keys())\n",
    "\n",
    "# Crear la matriz de confusión\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Visualizar la matriz de confusión\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar las curvas de entrenamiento\n",
    "def plot_history(history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs = range(1, min(len(acc), len(val_acc), len(loss), len(val_loss)) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Precisión\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, acc[:len(epochs)], 'b-', label='Precisión de entrenamiento')\n",
    "    plt.plot(epochs, val_acc[:len(epochs)], 'r-', label='Precisión de validación')\n",
    "    plt.title('Precisión de entrenamiento y validación')\n",
    "    plt.xlabel('Época')\n",
    "    plt.ylabel('Precisión')\n",
    "    plt.legend()\n",
    "\n",
    "    # Pérdida\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, loss[:len(epochs)], 'b-', label='Pérdida de entrenamiento')\n",
    "    plt.plot(epochs, val_loss[:len(epochs)], 'r-', label='Pérdida de validación')\n",
    "    plt.title('Pérdida de entrenamiento y validación')\n",
    "    plt.xlabel('Época')\n",
    "    plt.ylabel('Pérdida')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
